{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vitaldb\n",
    "import pyvital.arr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "from scipy import signal\n",
    "import scipy as sp\n",
    "import pyvital.filters.abp_ppv as f\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import random\n",
    "# df_trks = pd.read_csv('https://api.vitaldb.net/trks')  # read track list\n",
    "# df_cases = pd.read_csv(\"https://api.vitaldb.net/cases\")  # read case information\n",
    "# df_labs = pd.read_csv('https://api.vitaldb.net/labs')  # laboratory results\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import padasip as pa\n",
    "from scipy.signal import find_peaks\n",
    "from tsfresh.feature_extraction.feature_calculators import time_reversal_asymmetry_statistic\n",
    "import math\n",
    "import scipy\n",
    "import scipy.integrate\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "import pyvital\n",
    "from tsfresh.utilities.dataframe_functions import make_forecasting_frame\n",
    "from tsfresh import extract_features\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import pandas\n",
    "import smogn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scalar = StandardScaler()\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "import seaborn as sns\n",
    "from skrvm import RVR\n",
    "#import catboost as cb\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import xgboost\n",
    "from xgboost import XGBRegressor\n",
    "from scipy import signal\n",
    "import biosppy\n",
    "import neurokit2 as nk\n",
    "import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download tracks, cases, and labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 54 cases found\n"
     ]
    }
   ],
   "source": [
    "df_trks = pd.read_csv('https://api.vitaldb.net/trks')  # read track list\n",
    "df_cases = pd.read_csv(\"https://api.vitaldb.net/cases\")  # read case information\n",
    "df_labs = pd.read_csv('https://api.vitaldb.net/labs')  # laboratory results\n",
    "\n",
    "caseids_SNUADC_ART_Vigilance = list(\n",
    "    set(df_trks.loc[df_trks['tname'] == 'Vigilance/CO', 'caseid'] ) &\n",
    "    set(df_trks.loc[df_trks['tname'] == 'Vigilance/SV', 'caseid'] ) &\n",
    "    set(df_trks.loc[df_trks['tname'] == 'SNUADC/ART', 'caseid']) & \n",
    "    set(df_trks.loc[df_trks['tname'] == 'SNUADC/ECG_V5', 'caseid']) & \n",
    "    set(df_cases.loc[df_cases['age'] > 18, 'caseid'])   \n",
    ")\n",
    "\n",
    "print('Total {} cases found'.format(len(caseids_SNUADC_ART_Vigilance)))\n",
    "np.random.shuffle(caseids_SNUADC_ART_Vigilance)  # shuffle caseids"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define variables to store the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = []\n",
    "ABP = []\n",
    "ABP_current = []\n",
    "indexCO = []\n",
    "fullData = []\n",
    "CO = []\n",
    "CO_current = []\n",
    "check = 1\n",
    "patient_height = []\n",
    "patient_weight = []\n",
    "patient_age = []\n",
    "patient_sex = []\n",
    "patient_bmi = []\n",
    "HR = []\n",
    "HR_signal = []\n",
    "systolic_peaks = []\n",
    "onset_peaks = []\n",
    "notches = []\n",
    "nCardiac = 2\n",
    "art_smoothed = []\n",
    "data = []\n",
    "num_of_cases = 12\n",
    "num_of_samples = 3\n",
    "features = []\n",
    "counter = -1\n",
    "MAP = []\n",
    "length = []\n",
    "variance = []\n",
    "sum_of_derivative = []\n",
    "SD = []\n",
    "sys_pressure = []\n",
    "onset_pressure = []\n",
    "abnormals = []\n",
    "abn = 0\n",
    "nac_abn = []   \n",
    "segment = []\n",
    "patient_ppf = []\n",
    "ID = []\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for cases in range(0,len(caseids_SNUADC_ART_Vigilance)):\n",
    "  \n",
    "  nc = cases\n",
    "  valsEV1000 = np.array(vitaldb.load_case(caseids_SNUADC_ART_Vigilance[nc], ['SNUADC/ART','Vigilance/CO','Vigilance/SV','Vigilance/HR_AVG','SNUADC/ECG_V5'], 1/100)) # load cases that have ABP and CO and downsample it\n",
    "  patient_age.append(df_cases.at[caseids_SNUADC_ART_Vigilance[nc],'age'])\n",
    "  patient_weight.append(df_cases.at[caseids_SNUADC_ART_Vigilance[nc],'weight'])\n",
    "  patient_sex.append(df_cases.at[caseids_SNUADC_ART_Vigilance[nc],'sex'])\n",
    "  patient_height.append(df_cases.at[caseids_SNUADC_ART_Vigilance[nc],'height'])\n",
    "  patient_bmi.append(df_cases.at[caseids_SNUADC_ART_Vigilance[nc],'bmi'])\n",
    "  ID.append(caseids_SNUADC_ART_Vigilance[cases])\n",
    "\n",
    "  indexCO = np.array(np.where(~np.isnan(valsEV1000[:,2])))\n",
    "  print(cases)\n",
    "  loop = 300 # replace this by the number of samplse you want to upload. If you wish to download everything use loop = len(indexCO)\n",
    "  if len(indexCO[0]) < 300:\n",
    "    print('case does have enough data')\n",
    "    loop = len(indexCO[0])-round(len(indexCO[0])/700)\n",
    "                   \n",
    "  for ABP_sample in range(0,loop):\n",
    "    nac = ABP_sample\n",
    "    #collect art samples\n",
    "    ABP_current = np.array(valsEV1000[indexCO[0,nac]-1500:indexCO[0,nac],0]) # collect \"sample\" from ABP starting from the previous time CO is estimated up till the current estimation\n",
    "    #HR = np.array(valsEV1000[indexCO[0,nac]-1000:indexCO[0,nac],3])  \n",
    "    # collect hr samples\n",
    "    valid = True\n",
    "    validi = True\n",
    "    if (ABP_current > 200).any():\n",
    "      valid = False\n",
    "      #print(1)\n",
    "    elif(ABP_current < 30).any():\n",
    "      valid = False\n",
    "      #print(2)\n",
    "    elif np.max(ABP_current) - np.min(ABP_current) < 30:\n",
    "      valid = False\n",
    "      #print(3)\n",
    "    elif (np.abs(np.diff(ABP_current)) > 30).any():  # abrupt change -> noise\n",
    "      valid = False\n",
    "      #print(4)\n",
    "    elif np.isnan(ABP_current).any():\n",
    "      valid = False\n",
    "      #print(5)\n",
    "    if valid == False:\n",
    "      validi == False\n",
    "      nac_abn.append(nac)\n",
    "      #print(\"something went wrong\")\n",
    "    cnt = 0\n",
    "    while validi == False:\n",
    "        cnt = cnt + 1\n",
    "        if cnt == 100:\n",
    "           continue\n",
    "        nac = nac + 1\n",
    "        if nac >= len(indexCO[0]):\n",
    "           validi = True\n",
    "           continue\n",
    "        ABP_current = np.array(valsEV1000[indexCO[0,nac]-1500:indexCO[0,nac],0]) # collect \"sample\" from ABP starting from the previous time CO is estimated up till the current estimation\n",
    "        #HR = np.array(valsEV1000[indexCO[0,nac]-1000:indexCO[0,nac],3])  \n",
    "        # collect hr samples\n",
    "        validi = True\n",
    "        if (ABP_current > 200).any():\n",
    "            validi = False\n",
    "        elif(ABP_current < 30).any():\n",
    "            validi = False\n",
    "        elif np.max(ABP_current) - np.min(ABP_current) < 30:\n",
    "            validi = False\n",
    "        elif (np.abs(np.diff(ABP_current)) > 30).any():  # abrupt change -> noise\n",
    "            validi = False\n",
    "        # elif np.isnan(HR).any():\n",
    "        #     valid = False\n",
    "        elif np.isnan(ABP_current).any():   \n",
    "            validi = False  \n",
    "    if validi == False:\n",
    "       print(\"something went wrong\")\n",
    "       continue\n",
    "    \n",
    "    HR_current = np.array(valsEV1000[indexCO[0,nac],3])\n",
    "        # collect co samples\n",
    "    CO_current = np.array(valsEV1000[indexCO[0,nac],1])\n",
    "    SV_current = np.array(valsEV1000[indexCO[0,nac],2])\n",
    "    data = []\n",
    "    # print(ID[cases])\n",
    "    data = np.append(data, caseids_SNUADC_ART_Vigilance[cases])\n",
    "    data = np.append(data, HR_current)\n",
    "    data = np.append(data, CO_current)\n",
    "    data = np.append(data, SV_current)\n",
    "    data = np.append(data, patient_weight[cases])\n",
    "    data = np.append(data, patient_age[cases])\n",
    "    abn = 0\n",
    "    if df_cases.at[caseids_SNUADC_ART_Vigilance[nc],'sex'] == 'M':\n",
    "      data = np.append(data, 1) # if famle set 1\n",
    "    else:\n",
    "      data = np.append(data, 2) # if male set 2\n",
    "    data = np.append(data, patient_height[cases])\n",
    "    data = np.append(data, patient_bmi[cases])\n",
    "    data = np.append(data, ABP_current)\n",
    "    data = np.append(data, HR)\n",
    "    if ABP_sample == 0 and cases == 0:\n",
    "      segment = data\n",
    "    else:\n",
    "      segment = np.vstack([segment, data])\n",
    "        # append the values of art,hr,en co\n",
    "    # filter the signal\n",
    "df = pd.DataFrame(segment)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e7743e1e9445e066414ab2ce6c7de6e63f997835c955f4d5282448866e547bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
